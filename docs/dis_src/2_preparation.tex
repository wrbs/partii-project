% !TeX root = ../dissertation.tex
\chapter{Preparation}

The project has its theoretical foundation in the Compiler Construction and Optimising Compilers
course. Implementation of JIT compilation and garbage collection are beyond what is covered in the
Tripos.

OCaml has no specification (formal or otherwise) and a large part of project preparation was
familiarising myself with the low-level details of OCaml and gaining familiarity with the existing
runtime's source code.

\section{Technology choices}

The Rust programming language is not covered in the Tripos but I am already very familiar with
it from personal projects. Its combination of ML-like static type system, excellent performance
comparable to C and excellent FFI with C made it a good fit for this project. The language's
support
for algebraic data types and pattern matching (with the compiler verifying all cases are matched)
were particularly useful for the project.

Although many beginners to the language find themselves fighting the borrow checker I had used Rust
enough that I ran into no such problems. The language supports building high-level abstractions
while retaining performance.

x86\_64 assembly was new to me but did not prove too challenging to learn given my experience with
a variety of other architectures.

\section{The OCaml bytecode interpreter}

OCaml bytecode is interpreted by a stack-based abstract machine optimised for patterns in
functional programming. The OCaml runtime includes a generational, tracing and precise
stop-the-world garbage collector.

\subsection{Data representation}

OCaml has a uniform data representation for its \emph{values}. Values are 64\footnote{on 32-bit
    systems all of this is different, but this project only targets \texttt{x86\_64}} bits long.
Pointers to heap-allocated values are stored directly - but due to alignment they are guaranteed to
have a 0 in
the LSB. Integers are 63 bits long with the unused LSB storing a value of 1.

Every heap allocated value has a 64-bit header containing the number of words stored (called
the \texttt{wosize}) and a \texttt{u8} tag. Most tag values correspond to a block which can be
thought of as a tagged tuple containing \texttt{wosize} fields. Each field is treated as an OCaml
value by the garbage collector.

There are special tag values and cases in the garbage collector for things like floating point
numbers (which due to the uniform representation must be stored boxed on the heap),
closures, objects and \texttt{f64}/\texttt{u8} arrays.

\subsection{Registers}

The OCaml abstract machine uses five registers:

\begin{itemize}
    \item \texttt{sp} is a stack pointer for the OCaml stack which is used extensively
          in the bytecode.
    \item \texttt{accu} is an accumulator register used for the return values of functions
          and primitives as well as for most arithmetic operations.
    \item \texttt{env} holds a pointer to the current closure (an OCaml block) which is used for
          referencing closure variables (stored as fields in the block)
    \item \texttt{extra\_args} is used to mark the number of arguments passed on the stack
    \item \texttt{pc} contains the pointer to the bytecode instruction to be interpreted next
\end{itemize}

In addition to these registers there is the \texttt{Caml\_state} struct whose fields can be
considered as another 30 or so registers. They are used by the interpreter mainly for supporting
the garbage collector, exceptions and growing and reallocating the OCaml stack.

\subsection{Function calling model}

The interpreter traces its lineage from the ZINC Abstract Machine (ZAM) \cite{zinc} through various
iterations of the Caml system. The most significant feature of these abstract machines for this
project was the model used for calling functions and dealing with the functional language concept
of partial application.

\subsubsection{Eval-apply vs push-enter}

In a 2005 talk at the KAZAM workshop \cite{xavtalk}, Xavier Leroy describes the concept of a
distinction between the \emph{eval-apply} and \emph{push-enter} models. These models were
originally due to Simon Peyton Jones \cite{jones}\cite{marlow-jones}. This distinction has to do
with how functions deal with taking
multiple arguments and is particularly relevant to functions taking curried arguments.

In the eval-apply model (followed by most imperative programming languages like C, Java or Python
or
the OCaml native code backend) a function has a set number of arguments it takes. If a caller
provides more or less than the required arguments (partial application or calling a function
returned by a function) the caller must contain the code to handle these cases.

By contrast, in the push-enter model the callee must support any number of arguments passed to it.
This is the method used by the OCaml bytecode compiler and interpreter. The mechanism for doing
this is the combination of the stack and \texttt{extra\_args} register. The way the system works is
somewhat intricate and becomes relevant in this project in section \ref{dyn-recomp} where it is
explained in more detail.

\subsection{Garbage collector}

OCaml is a garbage collected language - memory is managed by the runtime and released once it is
no longer reachable from any other live object by the garbage collector (GC).

In the typical classification of tracing garbage collectors, the OCaml garbage collector is a
precise and generational stop-the-world garbage collector.

\subsubsection{Generational}

As OCaml is a functional language, short-lived immutable values are created and dropped very
frequently. For this reason OCaml uses a generational garbage collector: there is a minor heap and
a major heap. Allocations are done by pointer bump in the minor heap
until it becomes full. At that point the runtime branches into the garbage collector which compacts
anything alive in the minor heap.

Values that survie for some period of time are moved to the major heap which is collected much less
frequently.

OCaml requires a write barrier for every assignment to a field.

\subsubsection{Precise}

A precise tracing garbage collector can correctly identify every reference to an object and
determine exactly which values are pointers and which are other memory. In the OCaml interpreter
this is accomplished by storing all values on the OCaml stack and using the uniform data
representation to distinguish integers from pointers.

My initial compiler reuses the OCaml stack. The optimising compiler requires more sophisticated
handling, described in section \ref{gc-support}.

\subsubsection{Safepoints}

A useful abstraction in the implementation of code interacting with a GC is that of the safepoint.
This is a point in the program (usually a function call) where pointers might end up relocated.

For OCaml this can happen:

\begin{itemize}
    \item when the minor heap is full during an allocation and the allocation routine branches
          into
          the
          GC
    \item when a C primitive is called	(which may itself allocate memory and trigger the
          GC)
    \item when responding to signal handlers
\end{itemize}

As the garbage collector relocates objects, it is important the runtime can find all GC roots
(pointers to heap-allocated values). For the interpreter, all roots are stored on the stack. For
this reason the interpreter spills the accu and env to the stack at every safepoint.

\subsection{Instruction format} \label{ocaml-bytecode-format}

Opcodes and arguments are all stored as \texttt{i32} values. There are 149 distinct opcodes taking
various
different numbers of arguments.

However many opcodes are just the composition of a few simpler opcodes to save space in the format.
For example \texttt{PUSHGETGLOBALFIELD(x, y)} can be expanded to \texttt{PUSH,
    GETGLOBAL(x), GETFIELD(y)} or \texttt{ACC2} (only opcode) is the same as \texttt{ACC(2)}
(\texttt{ACC} opcode with the 2 as the operand).

\section{Compiler concepts}

A \emph{basic block} represents a sequence of instructions with only one entry and exit - all
instructions
in the block will be executed in order without any control flow.

These blocks are typically combined to make a data structure called a \emph{control flow graph}.
Each vertex represents a basic block and the (directed) edges represent the potential flow of
control between basic blocks.

\subsection{SSA form}

\textbf{Todo: add simple running example: if x = 2 then 5 else 7?}

A useful intermediate form used in compilers is single static assignment (SSA) form. If a program
is in this form,
every variable is assigned to only once and only binds a single immutable value.

This form is very useful to compiler writers as it can simplify the presentation and implementation
of many optimisations.

In order to allow for conditional branching in the program, the form needs some method to mark
choosing between values to use depending on the path taken through the program. The typical
method, as covered in the Optimising Compilers course, uses special Phi instructions to allow for
this type
of branching. The successor blocks have a node which marks the value that should be used in the
case
of each entry edge into the function.

Cranelift, and by extension this project, uses an alternative formulation known as block
parameters.
Here the blocks appear as if they are functions taking arguments and the values to use for the
arguments are provided by the predecessor block. This is a newer, slightly clearer formulation that
avoids having special case Phi node meta-instructions.

\section{x86\_64}

\begin{table}[h]
    \centering

    \begin{tabular}{ll}\toprule
        Argument registers     & rdi, rsi, rdx, rcx, r8, r9                \\
        Return registers       & rax, rdx                                  \\
        Stack alignment        & 16-byte at call                           \\
        Callee-saved registers & rax, rdi, rsi, rdx, rcx, r8, r9, r10, r11 \\
        Caller-saved registers & rbx, rsp, rbp, r12, r13, r14, r15         \\
        \bottomrule
    \end{tabular}

    \caption{Summary of the System V x86\_64 calling convention}
    \label{table:systemv}

\end{table}

x86\_64 is a large CISC (complex instruction set computer) architecture descending from the Intel
8086 processor.
It has 16 general purpose 64-bit registers: \texttt{r[abcd]x, rdi, rsi, rsp, rbp, r8-r15}.
This
project targets Linux only which uses the System V
calling convention.

A summary of the System V calling convention is given in Table \ref{table:systemv} --- the relevant
details for this dissertation are
that up to six 64-bit arguments can be passed to functions in registers, that up to two values may
be returned by a
function
and the large number of caller-saved registers.

Assembly listings in this project use Intel (\texttt{mov eax, 1}) rather than AT\&T (\texttt{movl
    \$1,\%eax}) syntax.

\section{Dependencies used}

\textbf{TODO - table with licenses}

I use a lot of open source libraries/crates (as is usual to do in Rust). Some dependencies needed
to be tweaked slightly and where that is the case they are vendored in to the source tree. Other
dependencies are included directly using \texttt{Cargo.toml}.

\subsection{Dynasm}

\textbf{TODO - Pull a bit out of impl for this}

\subsection{Cranelift}

The second compiler uses the \texttt{cranelift} \cite{cranelift} library which is a low-level
retargetable
code generator with an emphasis on use in JITs\footnote{It's largest use is for JIT-compiling
    webassembly as part of \texttt{wasmtime} and Firefox}. It is somewhat similar to LLVM but
lower
level and much simpler. It cannot perform many optimisations LLVM can but has significantly lower
compilation time.

\subsection{Sandmark}

I based my benchmark suite from the excellent Sandmark project by OCaml Labs at Cambridge. The
project consists of benchmark sources, build scripts (using \texttt{dune}), a benchmark runner,
compiler definitions (using \texttt{opam}) and a complicated \texttt{Makefile} to tie it all
together.  I made some larger changes to the tool to support bytecode benchmarks (the project
initially only benchmarked the native code compiler) but was able to reuse most of the machinery.

\section{Starting point}

Before the formal project start I forked the OCaml compiler (version 4.11.1) and implemented a
proof
of concept bidirectional FFI between C and Rust. This was done to mitigate the risk of not being
able to successfully link the OCaml runtime with Rust and helped build some familiarity with
OCaml's
existing runtime.

I also wrote a parser from the bytecode into Rust data types and a simple disassembler that uses
it. This allowed me to explore the undocumented bytecode format and begin to understand how higher
level OCaml constructs map to bytecode concepts.

Both components were largely rewritten during the formal time allocated to the project.

\textbf{TODO - make some kind of diff/way to really distinguish prior work}

\section{Development methodology}

\textbf{this is just an outline - todo expand}

Incremental method inspired by agile methods but simplified by only dealing with one developer.
Focus on working code as early as possible while slowly expanding out the feature set.

Some things were prototyped first before being rewritten with lessons learned from previous
implementation. Focus on tools to aid in understanding and gain familiarity with instruction set.
Tools could then be used in development.

Guided by major milestones.  Developed using my own machine. Code primarily in Rust with some
written in C. No modifications to the OCaml compiler source made - only OCaml. Some bash scripts
were used but more complicated scripts written in Rust.

Highly test-driven implementation strategy described in section \ref{impl-strategy}. Single Git
repository used for all aspects of the project including vendoring dependencies. The various build
systems of the OCaml compiler and Rust (\texttt{cargo}) were managed by top-level Makefiles. The
project is capable of being built by \texttt{opam} which helped with testing different compiler
configurations for benchmarking.

Expect tests used to compare output to snapshots and detect regressions - also serves as useful
documentation of 'what the compiler does'.

Backing up was done to GitHub. Monorepo. The repository contains everything needed to bootstrap the
project assuming a \texttt{x86\_64} Linux system with the required compilers and system libraries.
