% !TeX root = ../dissertation.tex
\chapter{Preparation}

\section{The OCaml bytecode interpreter}

OCaml bytecode is interpreted by a stack-based abstract machine optimised for patterns in
functional programming. The OCaml runtime includes a generational, tracing and precise
stop-the-world garbage collector.

\subsection{Data representation}

OCaml has a uniform data representation for its \emph{values}. Values are 64\footnote{on 32-bit
    systems all of this is different, but this project only targets \texttt{x86\_64}} bits long.
Pointers to heap-allocated values are stored directly - but due to alignment they are guaranteed to
have a 0 in
the LSB. Integers are 63 bits long with the unused LSB storing a value of 1.

Every heap allocated value has a 64-bit header containing the number of words stored (called
the \texttt{wosize}) and a \texttt{u8} tag. Most tag values correspond to a block which can be
thought of as a tagged tuple containing \texttt{wosize} fields. Each field is treated as an OCaml
value by the garbage collector.

There are special tag values and cases in the garbage collector for things like floating point
numbers\footnote{which due to the uniform representation must be stored boxed on the heap},
closures, objects and \texttt{f64}/\texttt{u8} arrays.

\subsection{Registers}

The OCaml abstract machine uses five registers:

\begin{itemize}
    \item \texttt{sp} is a stack pointer for the OCaml stack which is used extensively
          in the bytecode.
    \item \texttt{accu} is an accumulator register used for the return values of functions
          and primitives as well as for most arithmetic operations.
    \item \texttt{env} holds a pointer to the current closure (an OCaml block) which is used for
          referencing closure variables (stored as fields in the block)
    \item \texttt{extra\_args} is used to mark the number of arguments passed on the stack
    \item \texttt{pc} contains the pointer to the bytecode instruction to be interpreted next
\end{itemize}

In addition to these registers there is the \texttt{Caml\_state} struct whose fields can be
considered as another 30 or so registers. They are used by the interpreter mainly for supporting
the garbage collector, exceptions and growing and reallocating the OCaml stack.

\subsection{Core design decisions}

The interpreter traces its lineage from the ZINC Abstract Machine (ZAM) \cite{zinc} through various
iterations of the Caml system. The most significant feature of these abstract machines for this
project was the model used for calling functions and dealing with the functional language concept
of partial application.

\subsubsection{Eval-apply vs push-enter}

In a 2005 talk at the KAZAM workshop \cite{xavtalk}, Xavier Leroy describes the concept of a
distinction between the \emph{eval-apply} and \emph{push-enter} models. These models were
originally due to Simon Peyton Jones \cite{jones}\cite{marlow-jones}. This distinction has to do
with how functions deal with taking
multiple arguments and is particularly relevant to functions taking curried arguments.

In the eval-apply model (followed by most imperative programming languages like C, Java or Python
or
the OCaml native code backend) a function has a set number of arguments it takes. If a caller
provides more or less than the required arguments (partial application or calling a function
returned by a function) the caller must contain the code to handle these cases.

By contrast, in the push-enter model the callee must support any number of arguments passed to it.
This is the method used by the OCaml bytecode compiler and interpreter. The mechanism for doing
this is
the combination of the stack and \texttt{extra\_args} register. The way the system works is
somewhat intricate
and becomes relevant in this project in section \ref{dyn-recomp} where it is explained in more
detail.

% Consider a simple de Bruijin-indexed lambda calculus:
% 
% \begin{align*}
%     e \Coloneqq | & 0 | 1 | \ldots \qq{Variable} \\
%     |             & \lambda e \qq{Abstraction}   \\
%     |             & e\: e \qq{Application}       \\
% \end{align*}
% 
% \subsubsection{Simple scheme}
% 
% A simple scheme\footnote{Similar to that of the Part IB Compiler Construction course} is to define
% the following:
% 
% \newcommand{\compile}[1]{\ensuremath{\mathcal{C}\llbracket #1 \rrbracket}}
% 
% \begin{align*}
%     \compile{n}          & = \texttt{ACCESS}(n)                             \\
%     \compile{\lambda e}  & = \texttt{CLOSURE}(\compile{a}; \texttt{RETURN}) \\
%     \compile{e_1 \: e_2} & = \compile{e_1}; \compile{e_2}; \texttt{APPLY}   \\
% \end{align*}
% 
% The machine has code, an environment and a stack (where all behave someone like linked lists). The
% transitions are:
% 
% \begin{tabular}{llllll}\toprule
%     \multicolumn{3}{c}{Before} & \multicolumn{3}{c}{After}
%     \\\cmidrule(lr){1-3}\cmidrule(lr){4-6}
%     Code                       & Env                       & Stack                          & Code
%                                & Env                       & Stack
%     \\\midrule
%     \(\texttt{ACCESS}(n);c\)   & \(e\)                     & \(s\)                          & \(c\)
%                                & \(e\)                     & \(e(n);s\)
%     \\
%     \(\texttt{CLOSURE}(c');c\) & \(e\)                     & \(s\)                          & \(c\)
%                                & \(e\)                     & \(\langle c',
%     e'\rangle;s\)
%     \\
%     \(\texttt{APPLY};c\)       & \(e\)                     & \(v;\langle c', e\rangle ; s\) &
%     \(c'\)
%                                & \(v; e\)                  & \(c; e; s\)
%     \\
%     \(\texttt{RETURN}(n);c\)   & \(e\)                     & \(v;c';e';s\)                  &
%     \(c'\)
%                                & \(e'\)                    & \(v;s\)
%     \\\bottomrule
% \end{tabular}
% 
% \(\langle c, e\rangle\) denotes a closure
% 
% While conceptually simple, this module has problems with multiple argument curried functions.
% Calling any multiple-function argument requires creating
% and then discarding multiple closures. In order to deal with this we need special support.

\subsubsection{Implications}

The push-enter/`callee deals with arity mismatch' model was one of the biggest complexities
involved with
making this JIT. In the bytecode compiler every single call is an indirect lookup through a
closure, whereas the eval-apply model allows calls to be translated down to simple direct function
calls.

\subsection{Garbage collector}

OCaml is a garbage collected language - memory is managed by the runtime and released once it is
no longer reachable from any other live object by the garbage collector (GC).

In the typical classification of tracing garbage collectors, the OCaml garbage collector is a
precise and generational stop-the-world garbage collector.

\subsubsection{Generational}

As it is a functional language, short-lived immutable values are created and dropped very
frequently. For this reason OCaml uses a generational garbage collector: there is a minor heap and
a major heap. Allocations are done by pointer bump in the minor heap
until it becomes full. At that point the runtime branches into the garbage collector which compacts
anything alive in the minor heap.

After something survives for a while they are moved to the major heap which is collected much less
frequently.

OCaml also requires a write barrier for every assignment to a field.

\subsubsection{Precise}

A precise tracing garbage collector can correctly identify every reference to an object and
determine exactly which values are pointers and which are other memory. In the OCaml interpreter
this is accomplished by storing all values on the OCaml stack and using the uniform data
representation to distinguish integers from pointers.

My initial compiler reuses the OCaml stack. The optimising compiler requires more sophisticated
handling, described in section \ref{gc-support}.

\subsubsection{Safepoints}

A useful abstraction in the implementation of code interacting with a GC is that of the safepoint.
This is a point in the program (usually a function call) where pointers might end up relocated.

For OCaml this can happen:

\begin{itemize}
    \item when the minor heap is full during an allocation and the allocation routine branches
          into
          the
          GC
    \item when a C primitive is called	(which may itself allocate memory and trigger the
          GC)
    \item when responding to signal handlers
\end{itemize}

As the garbage collector relocates objects, it is important the runtime can find all GC roots
(pointers to heap-allocated values). For the interpreter, all roots are stored on the stack. For
this reason the interpreter spills the accu and env to the stack at every safepoint.

\subsection{Instruction format}

There are 149 opcodes defined. Each opcode takes a certain\footnote{or in the case of
    \texttt{SWITCH}, variable} number of arguments. Opcodes and arguments are stored as
\texttt{i32}
values.

However many opcodes are the composition of a few simpler opcodes to save space in the
format. For example \texttt{PUSHGETGLOBALFIELD(x, y)} can be expanded to \texttt{PUSH,
    GETGLOBAL(x), GETFIELD(y)} or \texttt{ACC2} (only opcode) is the same as \texttt{ACC(2)}
(with
the 2 as the operand).

For my JIT I did these expansions to arrive at 62 instructions\footnote{where all binary
    arithmetic and comparison instructions use the same instruction type -- so in practice about
    80 distinct instructions}.

Most operations are fairly standard for a stack based machine with an accumulator - there are
commands for stack manipulation and loading and storing the accumulator to the stack, performing
arithmetic using the accumulator and the stack, conditional branches, switch statements and
allocation of OCaml blocks. More complicated operations are done by using the \texttt{CCall*}
operations to call into primitives referenced in C.

\section{Compiler concepts}

Give overview of basic classical optimising compiler concepts like basic blocks, dataflow analysis
and SSA.

Describe the distinction between block parameters and Phi nodes.

\subsection{Basic blocks and control-flow graph}

Defn of basic block, back edges, numbering in reverse post-order.

\subsection{SSA form}

Defn of ssa form, benefits

\subsubsection{Phi nodes}

These are typical way to deal with things like if statements

\subsubsection{Block parameters}

These are newer (cite introducing paper) and slightly better - although largely the same concept.

\section{x86\_64}

\textbf{Give paragraph overview of the architecture. CISC. General purpose registers.}

\subsection{System V calling convention}

\textbf{Put in the table from osdev, highlight the callee-saved registers and multiple return
    values.}

\subsection{Frame pointers}

\textbf{Explain role of frame pointers \& \texttt{rbp}, why they are usually omitted and why we
    might want
    not do that}

\subsection{Assembly format}

\textbf{Give brief overview of intel/AT\&T difference. Say I'm using Intel because that's what
    \texttt{dynasm-rs} except for inline asm in C where GCC wants AT\&T.}

\section{Starting point}

\subsection{Before formal start}

Before formal project start I forked the OCaml compiler (version 4.11.1) and implemented a proof
of concept bidirectional FFI between C and Rust.

I also wrote a parser from the bytecode into Rust data types and a simple disassembler that uses
it.

Both components were rewritten during the formal time allocated to the project.

\textbf{TODO - make some kind of diff/way to really distinguish prior work}

\subsection{Dependencies used and forked}

I use a lot of open source libraries/crates (as is usual to do in Rust). Some dependencies needed
to
be tweaked slightly and where that is the case they are vendored in to the source tree. Other
dependencies are included directly using \texttt{Cargo.toml}.

I based my benchmark suite from the excellent Sandmark project by OCaml Labs at Cambridge. The
project consists of benchmark sources, build scripts (using \texttt{dune}), a benchmark runner,
compiler definitions (using \texttt{opam}) and a complicated \texttt{Makefile} to tie it all
together.  I made some larger changes to the tool to support bytecode benchmarks (the project
initially only benchmarked the native code compiler) but was able to reuse most of the machinery.
