function u0:0(r64, r64, r64) -> r64, i64 system_v {
    gv0 = symbol u1:0
    gv1 = symbol u1:1
    sig0 = (r64, r64, r64) -> r64, i64 system_v
    sig1 = (i64, i64, i64) system_v
    sig2 = (r64, i64) -> r64, i64 system_v
    sig3 = (r64, r64, r64) -> r64 system_v
    sig4 = (i64, r64) system_v
    fn0 = u0:1 sig0
    fn1 = %Memmove sig1
    fn2 = u0:2 sig2
    fn3 = u0:3 sig3
    fn4 = u0:4 sig4

block0(v0: r64, v1: r64, v2: r64):
    v22 -> v1
    v21 -> v2
    v4 = iconst.i64 0
    v33 -> v4
    v5 = symbol_value.i64 gv0
    v6 = iconst.i64 3
    v7 = raw_bitcast.r64 v6
    v8 = load.r64 notrap aligned v0+8
    v9, v10 = call fn0(v8, v1, v7)
    brz v10, block2(v9)
    jump block3

block3:
    v12 = load.i64 notrap aligned v5+152
    v34 = iconst.i64 -1
    v13 = iadd.i64 v10, v34
    v35 = iconst.i32 3
    v14 = ishl.i64 v10, v35
    v15 = iadd v12, v14
    v36 = iconst.i64 -24
    v16 = iadd v12, v36
    call fn1(v16, v12, v14)
    v17 = iconst.i64 1
    v18 = symbol_value.i64 gv1
    store notrap aligned v17, v15-8
    store notrap aligned v17, v15-16
    store notrap aligned v18, v15-24
    store notrap aligned v15, v5+152
    v19, v20 = call fn2(v9, v13)
    jump block2(v19)

block2(v11: r64):
    v23 = load.r64 notrap aligned v1
    v24 = load.r64 notrap aligned v1+8
    v25 = call fn3(v24, v23, v2)
    v26 = load.r64 notrap aligned v1
    v27 = raw_bitcast.i64 v26
    v37 = iconst.i64 2
    v28 = iadd v27, v37
    v29 = raw_bitcast.r64 v28
    v30 = raw_bitcast.i64 v1
    call fn4(v30, v29)
    v31 = iconst.i64 1
    v32 = raw_bitcast.r64 v31
    jump block1

block1:
    return v32, v4
}
