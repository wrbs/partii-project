function u0:0(r64, r64, r64, r64) -> r64, i64 system_v {
    gv0 = symbol u1:0
    gv1 = symbol u1:1
    sig0 = (i64, i32, i32, i64) system_v
    sig1 = (r64, r64, r64, r64) -> r64, i64 system_v
    sig2 = (i64, i64, i64) system_v
    sig3 = (r64, i64) -> r64, i64 system_v
    sig4 = (i64, i64, i64) system_v
    fn0 = u0:1 sig0
    fn1 = u0:2 sig1
    fn2 = %Memmove sig2
    fn3 = u0:3 sig3
    fn4 = %Memmove sig4

block0(v0: r64, v1: r64, v2: r64, v3: r64):
    v35 -> v1
    v52 -> v1
    v70 -> v1
    v5 = iconst.i64 0
    v15 -> v5
    v6 = symbol_value.i64 gv0
    v7 = load.r64 notrap aligned v0+8
    v8 = load.i64 notrap aligned v6
    v76 = iconst.i64 -72
    v9 = iadd v8, v76
    store notrap aligned v9, v6
    v10 = load.i64 notrap aligned v6+8
    v77 = icmp uge v9, v10
    brnz v77, block3(v9)
    jump block2

block2:
    v12 = iconst.i64 8
    v13 = iconst.i32 17
    v14 = iconst.i32 1
    call fn0(v12, v13, v14, v5)
    v16 = load.i64 notrap aligned v6
    jump block3(v16)

block3(v11: i64):
    v17 = iconst.i64 8439
    store notrap aligned v17, v11
    v78 = iconst.i64 8
    v18 = iadd v11, v78
    v19 = raw_bitcast.r64 v18
    store.r64 notrap aligned v7, v19+40
    store.r64 notrap aligned v2, v19+48
    store.r64 notrap aligned v3, v19+56
    v20 = raw_bitcast.i64 v19
    v21 = iconst.i64 0xdead_beef
    v23 -> v21
    v27 -> v21
    store notrap aligned v21, v20
    v22 = raw_bitcast.r64 v20
    v24 = iconst.i64 2297
    store notrap aligned v24, v20+8
    store notrap aligned v21, v20+16
    v79 = iconst.i64 16
    v25 = iadd v20, v79
    v26 = raw_bitcast.r64 v25
    v53 -> v26
    v28 = iconst.i64 4345
    store notrap aligned v28, v20+24
    store notrap aligned v21, v20+32
    v80 = iconst.i64 32
    v29 = iadd v20, v80
    v30 = raw_bitcast.r64 v29
    v71 -> v30
    v72 -> v30
    v31 = iconst.i64 9
    v48 -> v31
    v66 -> v31
    v32 = raw_bitcast.r64 v31
    v49 -> v32
    v67 -> v32
    v33 = iconst.i64 7
    v50 -> v33
    v68 -> v33
    v34 = raw_bitcast.r64 v33
    v51 -> v34
    v69 -> v34
    v36, v37 = call fn1(v22, v1, v34, v32)
    brz v37, block4(v36)
    jump block5

block5:
    v39 = load.i64 notrap aligned v6+152
    v81 = iconst.i64 -1
    v40 = iadd.i64 v37, v81
    v82 = iconst.i32 3
    v41 = ishl.i64 v37, v82
    v42 = iadd v39, v41
    v83 = iconst.i64 -24
    v43 = iadd v39, v83
    call fn2(v43, v39, v41)
    v44 = iconst.i64 1
    v45 = symbol_value.i64 gv1
    store notrap aligned v44, v42-8
    store notrap aligned v44, v42-16
    store notrap aligned v45, v42-24
    store notrap aligned v42, v6+152
    v46, v47 = call fn3(v36, v40)
    jump block4(v46)

block4(v38: r64):
    v54, v55 = call fn1(v26, v1, v34, v32)
    brz v55, block6(v54)
    jump block7

block7:
    v57 = load.i64 notrap aligned v6+152
    v84 = iconst.i64 -1
    v58 = iadd.i64 v55, v84
    v85 = iconst.i32 3
    v59 = ishl.i64 v55, v85
    v60 = iadd v57, v59
    v86 = iconst.i64 -24
    v61 = iadd v57, v86
    call fn4(v61, v57, v59)
    v62 = iconst.i64 1
    v63 = symbol_value.i64 gv1
    store notrap aligned v62, v60-8
    store notrap aligned v62, v60-16
    store notrap aligned v63, v60-24
    store notrap aligned v60, v6+152
    v64, v65 = call fn3(v54, v58)
    jump block6(v64)

block6(v56: r64):
    v73 = load.i64 notrap aligned v6+152
    v87 = iconst.i64 -24
    v74 = iadd v73, v87
    store.r64 notrap aligned v1, v74
    store.r64 notrap aligned v34, v74+8
    store.r64 notrap aligned v32, v74+16
    store notrap aligned v74, v6+152
    v75 = iconst.i64 3
    jump block1

block1:
    return v71, v75
}
