function u0:0(r64, i64, i64) -> r64, i64 system_v {
    gv0 = symbol u1:0
    gv1 = symbol u1:1
    sig0 = (r64, i64, i64, i64) -> r64, i64 system_v
    sig1 = (i64, i32, i32, i64) system_v
    fn0 = u0:1 sig0
    fn1 = u0:2 sig1

block0(v0: r64, v1: i64, v2: i64):
    v3 = null.r64 
    v4 = iconst.i64 0
    v5 = symbol_value.i64 gv0
    v6 = load.r64 notrap aligned v1
    v7 = iadd_imm v1, 8
    v8 = load.r64 notrap aligned v0+48
    v9 = load.r64 notrap aligned v0+40
    v10 = iconst.i64 1
    v11 = iconst.i64 1
    v12 = symbol_value.i64 gv1
    v13 = iadd_imm v7, -40
    store notrap aligned v8, v13
    store notrap aligned v6, v13+8
    store notrap aligned v12, v13+16
    store notrap aligned v11, v13+24
    store notrap aligned v11, v13+32
    v14, v15 = call fn0(v9, v10, v2, v13)
    v31 -> v14
    v34 -> v15
    v16 = load.r64 notrap aligned v0+32
    v36 -> v16
    v17 = load.r64 notrap aligned v0+24
    v30 -> v17
    v18 = load.i64 notrap aligned v5
    v19 = iadd_imm v18, -24
    store notrap aligned v19, v5
    v20 = load.i64 notrap aligned v5+8
    br_icmp ult v19, v20, block2
    jump block3(v19)

block2:
    v22 = iconst.i64 2
    v23 = iconst.i32 17
    v24 = iconst.i32 1
    v25 = iconst.i64 0
    call fn1(v22, v23, v24, v25)
    v26 = load.i64 notrap aligned v5
    jump block3(v26)

block3(v21: i64):
    v27 = iconst.i64 2052
    store notrap aligned v27, v21
    v28 = iadd_imm v21, 8
    v29 = raw_bitcast.r64 v28
    store.r64 notrap aligned v17, v29
    store.r64 notrap aligned v14, v29+8
    v32 = load.r64 notrap aligned v0+16
    v33 = load.r64 notrap aligned v0+8
    v35 = iadd_imm.i64 v15, -24
    store notrap aligned v32, v35
    store notrap aligned v29, v35+8
    store.r64 notrap aligned v16, v35+16
    v37 = iconst.i64 3
    jump block1

block1:
    store.i64 notrap aligned v35, v2
    return v33, v37
}
