function u0:0(r64, i64) -> r64, i64 system_v {
    gv0 = symbol u1:0
    gv1 = symbol u1:1
    sig0 = (i64, i32, i32, i64) system_v
    fn0 = u0:1 sig0

block0(v0: r64, v1: i64):
    v2 = null.r64 
    v3 = iconst.i64 0
    v4 = symbol_value.i64 gv0
    v5 = load.r64 notrap aligned v1
    v6 = load.r64 notrap aligned v1+8
    v7 = load.r64 notrap aligned v1+16
    v8 = iadd_imm v1, 24
    v30 -> v8
    v9 = load.r64 notrap aligned v7
    v33 -> v9
    v10 = iconst.i64 1
    v11 = raw_bitcast.r64 v10
    v32 -> v11
    v12 = load.i64 notrap aligned v4
    v13 = iadd_imm v12, -32
    store notrap aligned v13, v4
    v14 = load.i64 notrap aligned v4+8
    br_icmp ult v13, v14, block2
    jump block3(v13)

block2:
    v16 = iconst.i64 3
    v17 = iconst.i32 17
    v18 = iconst.i32 1
    v19 = iconst.i64 0
    call fn0(v16, v17, v18, v19)
    v20 = load.i64 notrap aligned v4
    jump block3(v20)

block3(v15: i64):
    v21 = iconst.i64 3319
    store notrap aligned v21, v15
    v22 = iadd_imm v15, 8
    v23 = raw_bitcast.r64 v22
    store.r64 notrap aligned v5, v23+8
    store.r64 notrap aligned v6, v23+16
    v24 = raw_bitcast.i64 v23
    v25 = iconst.i64 0xdead_beef
    store notrap aligned v25, v24
    v26 = symbol_value.i64 gv1
    v27 = load.i64 notrap aligned v26
    v28 = load.r64 notrap aligned v27+2384
    v29 = load.r64 notrap aligned v28+48
    v31 = iadd_imm.i64 v8, -24
    store notrap aligned v23, v31
    store.r64 notrap aligned v11, v31+8
    store.r64 notrap aligned v9, v31+16
    v34 = iconst.i64 3
    jump block1

block1:
    store.i64 notrap aligned v31, v4+152
    return v29, v34
}
